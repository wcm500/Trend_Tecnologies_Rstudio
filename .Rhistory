#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()%>%
str_replace_all("[^[:alpha:][:space:]]*", "")
#Eliminar los pescios en blanco
rtext = rtext[!rtext %in% c("")]
#install.packages("readtext")
library(readtext)
library(tm)
library(stringr)
library(ggplot2)
library(ggrepel)
library(dplyr)
library("wordcloud")
#install.packages("ggrepel")
#install.packages("syuzhet")
library(syuzhet)
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()%>%
str_replace_all("[^[:alpha:][:space:]]*", "")
#Eliminar los pescios en blanco
rtext = rtext[!rtext %in% c("")]
rtext = rtext[!rtext %in% c("will","use","can","technolog","new")]
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()%>%
str_replace_all("[^[:alpha:][:space:]]*", "")
#Eliminar los pescios en blanco
rtext = rtext[!rtext %in% c("")]
rtext_corpus <- VCorpus(VectorSource(rtext))
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus_clean)
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
comentarios_palabras <- rtext_data_dtm$dimnames
comentarios_palabras
wordfreqs <- rtext_data_dtm$dimnames$Terms %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
wordfreqs <- rtext %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
#Las 15 palabras mas frecuentes y sus frecuencias para graficar
wfd <- table(rtext)
wfd <- wfd[order(wfd, decreasing = T)]
wfd <- wfd[1:15]
View(wfd)
#Pasar a dataframe para generar visualizaciones con GGPLOT
wfd <- as.data.frame(wfd)
#Grafico en barras para ver las palabras mas comun
ggplot(data=wfd, aes(x=rtext, y=Freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=Freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()%>%
str_replace_all("[^[:alpha:][:space:]]*", "") %>%
c("")
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()%>%
str_replace_all("[^[:alpha:][:space:]]*", "") %>%
c("","will","use","can","technolog","new") # eliminar palabras determinadas por cuenta propia.
#Tabla para crear las plabras con frecuencias
wordfreqs <- rtext %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()%>%
str_replace_all("[^[:alpha:][:space:]]*", "") %>%
c("","will","use","can","technolog","new") # eliminar palabras determinadas por cuenta propia.
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()%>%
str_replace_all("[^[:alpha:][:space:]]*", "") %>%
c("") %>%
c("will","use","can","technolog","new")
#Tabla para crear las plabras con frecuencias
wordfreqs <- rtext %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
#Eliminar los pescios en blanco
rtext = rtext[!rtext %in% c("")]
wordfreqs <- rtext %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
# create wordcloud
wordcloud(words = wordfreqs$Palabras, freq = wordfreqs$Frecuencia,
max.words=150, scale=c(3,.9),random.order=FALSE, rot.per=0.30,
colors=brewer.pal(6, "BrBG"))
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()%>%
str_replace_all("[^[:alpha:][:space:]]*", "")
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()%>%
str_replace_all("[^[:alpha:][:space:]]*", "")
#Eliminar los pescios en blanco
rtext = rtext[!rtext %in% c("")]
rtext_corpus <- VCorpus(VectorSource(rtext))
#eliminar stop words
rtext = rtext[!rtext %in% c("will","use","can","technolog","new")]
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()%>%
str_replace_all("[^[:alpha:][:space:]]*", "")
#Eliminar los pescios en blanco
rtext = rtext[!rtext %in% c("")]
rtext_corpus <- VCorpus(VectorSource(rtext))
rtext_corpus_clean <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),"will","can"))
comentarios_palabras <- rtext_data_dtm$dimnames
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
comentarios_palabras <- rtext_data_dtm$dimnames
wordfreqs <- rtext_data_dtm$dimnames$Terms %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
wordfreqs <- rtext %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
rtext_corpus_clean <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),"will","can"))
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus_clean)
comentarios_palabras <- rtext_data_dtm$dimnames
wordfreqs <- rtext_data_dtm$dimnames$Terms %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
wordfreqs <- rtext %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
#Las 15 palabras mas frecuentes y sus frecuencias para graficar
wfd <- table(rtext)
wfd <- wfd[order(wfd, decreasing = T)]
wfd <- wfd[1:15]
View(wfd)
#Pasar a dataframe para generar visualizaciones con GGPLOT
wfd <- as.data.frame(wfd)
#Grafico en barras para ver las palabras mas comun
ggplot(data=wfd, aes(x=rtext, y=Freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=Freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
# create wordcloud
wordcloud(words = wordfreqs$Palabras, freq = wordfreqs$Frecuencia,
max.words=150, scale=c(3,.9),random.order=FALSE, rot.per=0.30,
colors=brewer.pal(6, "BrBG"))
stopwords <-  c("will","use","can","technolog","new")
rtext_corpus_clean <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),stopwords))
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus_clean)
comentarios_palabras <- rtext_data_dtm$dimnames
wordfreqs <- rtext_data_dtm$dimnames$Terms %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
wordfreqs <- rtext %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
rtext_corpus_clean <- tm_map(abs,rtext_corpus, removeWords, c(stopwords("english"),stopwords))
myStopwords <- c(stopwords('english'),"will","use","can","technolog","new")# to add words
myStopwords <- c(stopwords('english'),"will","use","can","technolog","new")# to add words
rtext_corpus_clean <- tm_map(rtext_corpus, removeWords,myStopwords )
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus_clean)
comentarios_palabras <- rtext_data_dtm$dimnames
wordfreqs <- rtext_data_dtm$dimnames$Terms %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
wordfreqs <- rtext %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
rtext_data_dtm$dimnames$Terms
wordfreqs <- rtext_data_dtm$dimnames$Terms %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
#Las 15 palabras mas frecuentes y sus frecuencias para graficar
wfd <- table(rtext)
wfd <- wfd[order(wfd, decreasing = T)]
wfd <- wfd[1:15]
View(wfd)
comentarios_palabras
wordfreqs <- rtext_data_dtm$dimnames$Terms %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
#Las 15 palabras mas frecuentes y sus frecuencias para graficar
wfd <- table(comentarios_palabras)
#Las 15 palabras mas frecuentes y sus frecuencias para graficar
wfd <- table(rtext_data_dtm$dimnames$Terms)
wfd <- wfd[order(wfd, decreasing = T)]
wfd <- wfd[1:15]
View(wfd)
#Pasar a dataframe para generar visualizaciones con GGPLOT
wfd <- as.data.frame(wfd)
#Grafico en barras para ver las palabras mas comun
ggplot(data=wfd, aes(x=rtext, y=Freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=Freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
#Grafico en barras para ver las palabras mas comun
ggplot(data=wfd, aes(x=rtext_data_dtm$dimnames$Terms, y=Freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=Freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
#Grafico en barras para ver las palabras mas comun
ggplot(data=wfd, aes(x=Var1, y=Freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=Freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
wordfreqs <- comentarios_palabras %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
comentarios_palabras
wordfreqs <- comentarios_palabras$Terms %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
wordfreqs <- rtext %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
#Las 15 palabras mas frecuentes y sus frecuencias para graficar
wfd <- table(rtext_data_dtm$dimnames$Terms)
matriz <- as.matrix(rtext_data_dtm)
matrizOrdenada <- sort(rowSums(matriz),decreasing=TRUE)
dataframePalabras <- data.frame(palabra = comentarios_palabras$Terms[matrizOrdenada],freq=matrizOrdenada)
matriz <- as.matrix(rtext_data_dtm)
matrizOrdenada <- sort(rowSums(matriz),decreasing=TRUE)
dataframePalabras <- data.frame(palabra = comentarios_palabras$Terms,freq=matrizOrdenada)
head(dataframePalabras, 10)
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()%>%
str_replace_all("[^[:alpha:][:space:]]*", "")
#Eliminar los pescios en blanco
rtext = rtext[!rtext %in% c("")]
myStopwords <- c(stopwords('english'),"will","use","can","technolog","new")# to add words
rtext = rtext[!rtext %in% c("", myStopwords)]
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()%>%
str_replace_all("[^[:alpha:][:space:]]*", "")
#Eliminar los pescios en blanco
myStopwords <- c(stopwords('english'),"will","use","can","technolog","new")# to add words
rtext = rtext[!rtext %in% c("", myStopwords)]
rtext_corpus <- VCorpus(VectorSource(rtext))
rtext_corpus_clean <- tm_map(rtext_corpus, removeWords,myStopwords )
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus_clean)
comentarios_palabras <- rtext_data_dtm$dimnames
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
wordfreqs <- rtext %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
#Eliminar los pescios en blanco
myStopwords <- c(stopwords('english'),"will","use","can","technolog","new")# to add words
rtext = rtext[!rtext %in% c("",myStopwords)]
rtext_corpus <- VCorpus(VectorSource(rtext))
wordfreqs <- rtext %>%
table() %>%
as.data.frame() %>%
arrange(desc(Freq))
colnames(wordfreqs) <- c("Palabras", "Frecuencia")
head(wordfreqs)
#Las 15 palabras mas frecuentes y sus frecuencias para graficar del 1 al 15
wfd <- table(rtext)
wfd <- wfd[order(wfd, decreasing = T)]
wfd <- wfd[1:15]
View(wfd)
#Pasar a dataframe para generar visualizaciones con GGPLOT
wfd <- as.data.frame(wfd)
#Grafico en barras para ver las palabras mas comun
ggplot(data=wfd, aes(x=Var1, y=Freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=Freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
#Grafico en barras para ver las palabras mas comun
ggplot(data=wfd, aes(x=rtext, y=Freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=Freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
# create wordcloud
wordcloud(words = wordfreqs$Palabras, freq = wordfreqs$Frecuencia,
max.words=150, scale=c(3,.9),random.order=FALSE, rot.per=0.30,
colors=brewer.pal(6, "BrBG"))
#Frecuencia relativa (Falta)
ggplot(wfd, aes(x=rtext, y=Freq, group =1)) +
geom_smooth(aes(y = Freq, x = rtext), color = "goldenrod2")+
geom_line(aes(y = Freq, x = rtext), color = "indianred4") +
guides(color=guide_legend(override.aes=list(fill=NA))) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))+
scale_y_continuous(name ="Relative Frequency (per 1,000 words)")
