freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
# Tabla de frecuencias ordenada limpia
wf <- data.frame(word=names(freq), freq=freq)
head(wf)
ggplot(subset(wf, freq>25), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=Freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
ggplot(subset(wf, freq>25), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
ggplot(subset(wf, freq>15), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
ggplot(subset(wf, freq>25), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=-90, hjust=0))
ggplot(subset(wf, freq>15), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
ggplot(subset(wf, freq<15), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
head(wf)
#Grafico en barras para ver las palabras mas comun
ggplot(data=wfd, aes(x=rtext, y=Freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=Freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
ggplot(subset(wf, freq>28), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")
rtext_corpus <- VCorpus(VectorSource(rtext$text))
rtext_corpus <- tm_map(rtext_corpus, content_transformer(tolower))
rtext_corpus <- tm_map(rtext_corpus, removeNumbers)
rtext_corpus <- tm_map(rtext_corpus, removeWords, c(stopwords("english"), "will","use","can","technolog","new"))
rtext_corpus <- tm_map(rtext_corpus, removePunctuation)
rtext_corpus <- tm_map(rtext_corpus, stemDocument)
rtext_corpus <- tm_map(rtext_corpus, stripWhitespace)
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm, 0.2) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
#________________________________________________________________________________
#Analisis con corpus
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")
rtext_corpus <- VCorpus(VectorSource(rtext$text))
rtext_corpus <- tm_map(rtext_corpus, content_transformer(tolower))
rtext_corpus <- tm_map(rtext_corpus, removeNumbers)
rtext_corpus <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),"will","use","can","technolog","new"))
rtext_corpus <- tm_map(rtext_corpus, removePunctuation)
rtext_corpus <- tm_map(rtext_corpus, stemDocument)
rtext_corpus <- tm_map(rtext_corpus, stripWhitespace)
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm, 0.2) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
myStopWords<- c("will","use","can","technolog","new")
rtext_corpus <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),myStopWords))
rtext_corpus <- tm_map(rtext_corpus, removePunctuation)
rtext_corpus <- tm_map(rtext_corpus, stemDocument)
rtext_corpus <- tm_map(rtext_corpus, stripWhitespace)
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm, 0.2) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
wf <- data.frame(word=names(freq), freq=freq)
head(wf)
wfd <- table(rtext)
wfd <- wfd[order(wfd, decreasing = T)]
wfd <- wfd[1:15]
View(wfd)
#Pasar a dataframe para generar visualizaciones con GGPLOT
wfd <- as.data.frame(wfd)
View(wfd)
ggplot(subset(wf, freq>28), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
rtext
head(wf)
wfd <- table(wf)
wfd <- wfd[order(wfd, decreasing = T)]
wfd <- wfd[1:15]
View(wfd)
#Pasar a dataframe para generar visualizaciones con GGPLOT
wfd <- as.data.frame(wfd)
ggplot(subset(wf, freq>28), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
ggplot(subset(wf, freq>28), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme_minimal(axis.text.x=element_text(angle=-90, hjust=0))+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
ggplot(subset(wf, freq>28), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme(axis.text.x=element_text(angle=-90, hjust=0))+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
head(wf)
wf <- data.frame(word=names(freq), freq=freq)
freq
# Visualizar text data-words con word-cloud visualizacion
wordcloud(rtext_corpus,
min.freq = 25, #frecuencia minima
scale = c(3, 0.5),
random.order = FALSE)
# Visualizar text data-words con word-cloud visualizacion
wordcloud(rtext_corpus,
max.words=150, scale=c(3,.9),random.order=FALSE, rot.per=0.30,
colors=brewer.pal(6, "BrBG"))
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()%>%
str_replace_all("[^[:alpha:][:space:]]*", "")
view(rtext)
rtext
#Eliminar los pescios en blanco & stopwords
myStopwords <- c(stopwords('english'),"will","use","can","technolog","new")# to add words
rtext = rtext[!rtext %in% c("",myStopwords)]
rtext
#crear elcorpus despues de la limpieza de texto
rtext_corpus <- VCorpus(VectorSource(rtext$text))
#crear elcorpus despues de la limpieza de texto
rtext_corpus <- VCorpus(VectorSource(rtext))
#rtext_corpus_clean <- tm_map(rtext_corpus, removeWords,myStopwords )
#rtext_data_dtm <- DocumentTermMatrix(rtext_corpus_clean)
#comentarios_palabras <- rtext_data_dtm$dimnames
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm, 0.2) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
wf <- data.frame(word=names(freq), freq=freq)
head(wf)
#________________________________________________________________________________
#Analisis con corpus
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")
rtext_corpus <- VCorpus(VectorSource(rtext$text))
rtext_corpus <- tm_map(rtext_corpus, content_transformer(tolower))
rtext_corpus <- tm_map(rtext_corpus, removeNumbers)
myStopWords<- c("will","use","can","technolog","new")
rtext_corpus <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),myStopWords))
rtext_corpus <- tm_map(rtext_corpus, removePunctuation)
rtext_corpus <- tm_map(rtext_corpus, stemDocument)
rtext_corpus <- tm_map(rtext_corpus, stripWhitespace)
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
#________________________________________________________________________________
#Analisis con corpus
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")
rtext_corpus <- VCorpus(VectorSource(rtext$text))
rtext_corpus <- tm_map(rtext_corpus, content_transformer(tolower))
rtext_corpus <- tm_map(rtext_corpus, removeNumbers)
myStopWords<- c("will","use","can","technolog","new")
rtext_corpus <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),myStopWords))
rtext_corpus <- tm_map(rtext_corpus, removePunctuation)
rtext_corpus <- tm_map(rtext_corpus, stemDocument)
rtext_corpus <- tm_map(rtext_corpus, stripWhitespace)
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
wf <- data.frame(word=names(freq), freq=freq)
head(wf)
#________________________________________________________________________________
#Analisis con corpus
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")
rtext_corpus <- VCorpus(VectorSource(rtext$text))
rtext_corpus <- tm_map(rtext_corpus, content_transformer(tolower))
rtext_corpus <- tm_map(rtext_corpus, removeNumbers)
myStopWords<- c("will","use","can","technolog","new")
rtext_corpus <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),myStopWords))
rtext_corpus <- tm_map(rtext_corpus, removePunctuation)
rtext_corpus <- tm_map(rtext_corpus, stemDocument)
rtext_corpus <- tm_map(rtext_corpus, stripWhitespace)
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm,0.009) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
#________________________________________________________________________________
#Analisis con corpus
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")
rtext_corpus <- VCorpus(VectorSource(rtext$text))
rtext_corpus <- tm_map(rtext_corpus, content_transformer(tolower))
rtext_corpus <- tm_map(rtext_corpus, removeNumbers)
myStopWords<- c("will","use","can","technolog","new")
rtext_corpus <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),myStopWords))
rtext_corpus <- tm_map(rtext_corpus, removePunctuation)
rtext_corpus <- tm_map(rtext_corpus, stemDocument)
rtext_corpus <- tm_map(rtext_corpus, stripWhitespace)
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm,0.009) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
wf <- data.frame(word=names(freq), freq=freq)
head(wf)
#________________________________________________________________________________
#Analisis con corpus
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")
rtext_corpus <- VCorpus(VectorSource(rtext$text))
rtext_corpus <- tm_map(rtext_corpus, content_transformer(tolower))
rtext_corpus <- tm_map(rtext_corpus, removeNumbers)
myStopWords<- c("will","use","can","technolog","new")
rtext_corpus <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),myStopWords))
rtext_corpus <- tm_map(rtext_corpus, removePunctuation)
rtext_corpus <- tm_map(rtext_corpus, stemDocument)
rtext_corpus <- tm_map(rtext_corpus, stripWhitespace)
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm,0.009) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
#________________________________________________________________________________
#Analisis con corpus
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")
rtext_corpus <- VCorpus(VectorSource(rtext$text))
rtext_corpus <- tm_map(rtext_corpus, content_transformer(tolower))
rtext_corpus <- tm_map(rtext_corpus, removeNumbers)
myStopWords<- c("will","use","can","technolog","new")
rtext_corpus <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),myStopWords))
rtext_corpus <- tm_map(rtext_corpus, removePunctuation)
rtext_corpus <- tm_map(rtext_corpus, stemDocument)
rtext_corpus <- tm_map(rtext_corpus, stripWhitespace)
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm,0.2) # 20% de espacio vacio maximo
rtext_data_dtm
rtext_data_dtm
#________________________________________________________________________________
#Analisis con corpus
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")
rtext_corpus <- VCorpus(VectorSource(rtext$text))
rtext_corpus <- tm_map(rtext_corpus, content_transformer(tolower))
rtext_corpus <- tm_map(rtext_corpus, removeNumbers)
myStopWords<- c("will","use","can","technolog","new")
rtext_corpus <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),myStopWords))
rtext_corpus <- tm_map(rtext_corpus, removePunctuation)
rtext_corpus <- tm_map(rtext_corpus, stemDocument)
rtext_corpus <- tm_map(rtext_corpus, stripWhitespace)
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm,0.2) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
wf <- data.frame(word=names(freq), freq=freq)
head(wf)
wfd <- table(wf)
ggplot(subset(wf, freq[1:15]), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme(axis.text.x=element_text(angle=-90, hjust=0))+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
ggplot(subset(wf, freq), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme(axis.text.x=element_text(angle=-90, hjust=0))+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
ggplot(subset(wf, freq>25), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme(axis.text.x=element_text(angle=-90, hjust=0))+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()
rtext
#Eliminar los pescios en blanco & stopwords
myStopwords <- c(stopwords('english'),"will","use","can","technolog","new")# to add words
rtext = rtext[!rtext %in% c("",myStopwords)]
rtext
#crear elcorpus despues de la limpieza de texto
rtext_corpus <- VCorpus(VectorSource(rtext$text))
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm,0.2) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
rtext_corpus <- tm_map(rtext_corpus, stemDocument)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm,0.2) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
#Crear la corpora con los PDFs
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")%>%
tolower() %>%
removeWords(stopwords("english")) %>%
strsplit(" ") %>%
unlist() %>% #producir un vector
stemDocument()%>%
removeNumbers()%>%
stripWhitespace()%>%
removePunctuation()
rtext
#Eliminar los pescios en blanco & stopwords
myStopwords <- c(stopwords('english'),"will","use","can","technolog","new")# to add words
rtext = rtext[!rtext %in% c("",myStopwords)]
#crear elcorpus despues de la limpieza de texto
rtext_corpus <- VCorpus(VectorSource(rtext))
rtext_corpus
rtext_corpus <- VCorpus(VectorSource(rtext$text))
#________________________________________________________________________________
#Analisis con corpus
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")
rtext_corpus <- VCorpus(VectorSource(rtext$text))
rtext_corpus <- tm_map(rtext_corpus, content_transformer(tolower))
rtext_corpus <- tm_map(rtext_corpus, removeNumbers)
myStopWords<- c("will","use","can","technolog","new")
rtext_corpus <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),myStopWords))
rtext_corpus <- tm_map(rtext_corpus, removePunctuation)
rtext_corpus <- tm_map(rtext_corpus, stemDocument)
rtext_corpus <- tm_map(rtext_corpus, stripWhitespace)
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm,0.2) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
#________________________________________________________________________________
#Analisis con corpus
rtext <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")
rtext
rtext_corpus <- VCorpus(VectorSource(rtext$text))
rtext_corpus
rtext_corpus <- tm_map(rtext_corpus, content_transformer(tolower))
rtext_corpus <- tm_map(rtext_corpus, removeNumbers)
myStopWords<- c("will","use","can","technolog","new")
myStopWords
myStopWords<- c(will,use,can,"technolog","new")
myStopWords<- c("will","use","can","technolog","new")
stopwords
stopwords("english")
rtext_corpus <- tm_map(rtext_corpus, removeWords, c(stopwords("english"),myStopWords))
rtext_corpus <- tm_map(rtext_corpus, removePunctuation)
rtext_corpus <- tm_map(rtext_corpus, stemDocument)
rtext_corpus <- tm_map(rtext_corpus, stripWhitespace)
rtext_data_dtm <- DocumentTermMatrix(rtext_corpus)
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm,0.2) # 20% de espacio vacio maximo
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
wf <- data.frame(word=names(freq), freq=freq)
head(wf)
ggplot(subset(wf, freq>25), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme(axis.text.x=element_text(angle=-90, hjust=0))+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
# Visualizar text data-words con word-cloud visualizacion
wordcloud(rtext_corpus,
max.words=150, scale=c(3,.9),random.order=FALSE, rot.per=0.30,
colors=brewer.pal(6, "BrBG"))
rtext$text
# Ambiente de trabajo
setwd("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology") # se tiene que editar
getwd() # comprobacion
# Leer texto del pdf
pdfs <- readtext("D:/Mineria de datos/PROYECTO FINAL/Trend_Tecnologies_Rstudio/PDF Technology")
# Creacion del corpus
corpus <- VCorpus(VectorSource(pdfs$text))
corpus
# Eliminar columna identificadora
pdfs <- pdfs[-1]
#==========================================LIMPIEZA DE DATOS=================================================
# Pasar todo el texto a minuscula
corpus <- tm_map(corpus, content_transformer(tolower))
# Remover numbers
corpus <- tm_map(corpus, removeNumbers)
# Remover 'stop words'
corpus <- tm_map(corpus, removeWords, stopwords("english"))
# Remover puntuacion
corpus <- tm_map(corpus, removePunctuation)
# Remover prefijos
corpus <- tm_map(corpus, stemDocument)
# Eliminar espacio en blanco innecesario
corpus <- tm_map(corpus, stripWhitespace)
#=============================================================================================================
# Crear un data matrix
dtm <- DocumentTermMatrix(corpus)
dtm <- removeSparseTerms(dtm, 0.2) # 20% de espacio vacio maximo
dtm
# Crear tabla de frecuencias ordenada
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
freq
# Tabla de frecuencias ordenada limpia
wf <- data.frame(word=names(freq), freq=freq)
head(wf)
#========================================REPRESENTACION GRAFICA DE FRECUENCIAS(PLOT Y WORDCLOUD)=====================================================
# Plot de barras para apreciarlo de forma ordenada
ggplot(subset(wf, freq>25), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=-90, hjust=0))
# Visualizar text data-words con word-cloud visualizacion
wordcloud(corpus,
min.freq = 25, #frecuencia minima
scale = c(3, 0.5),
random.order = FALSE)
#========================================REPRESENTACION GRAFICA DE FRECUENCIAS(PLOT Y WORDCLOUD)=====================================================
# Plot de barras para apreciarlo de forma ordenada
ggplot(subset(wf, freq>25), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat = "identity") +
theme(axis.text.x=element_text(angle=-90, hjust=0))
rtext_data_dtm <- removeSparseTerms(rtext_data_dtm,0.01) # 1% de uso menor eliminado
rtext_data_dtm
freq <- sort(colSums(as.matrix(rtext_data_dtm)), decreasing=TRUE)
freq
wf <- data.frame(word=names(freq), freq=freq)
head(wf)
ggplot(subset(wf, freq>25), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme(axis.text.x=element_text(angle=-90, hjust=0))+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
ggplot(subset(wf, freq>25), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme(axis.text.x=element_text(angle=-90, hjust=0))+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
ggplot(subset(wf, freq>30), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme(axis.text.x=element_text(angle=-90, hjust=0))+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
ggplot(subset(wfd, freq>30), aes(x = reorder(word, -freq), y = freq)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=freq), vjust=1.6, color="white", size=3.5)+
theme(axis.text.x=element_text(angle=-90, hjust=0))+
theme_minimal()+
labs(x = "Palabra",
y = "Frecuencia de las palabras",
title = "Palabras mas repetidas")
wordcloud(rtext_corpus,
max.words=150, scale=c(3,.9),random.order=FALSE, rot.per=0.30,
colors=brewer.pal(6, "BrBG"))
wordcloud(rtext_corpus,
max.words=150, scale=c(3,.9),random.order=FALSE, rot.per=0.30,
colors=brewer.pal(6, "BrBG"))
